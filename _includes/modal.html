<!-- Modal window -->
<div id="project-modal" class="modal">
    <div class="modal-overlay"></div>
    <div class="modal-content">
        <button class="modal-close">&times;</button>
        <div class="modal-body">
            <h2 class="modal-title"></h2>
            <div class="modal-description"></div>
        </div>
    </div>
</div>

<script>
    const projectDetails = {
        'monarch': {
            title: 'Monarch Endoscopic Surgical Platform',
            sections: {
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                            <p>The Monarch Platform represents a significant advancement in robotic-assisted surgery, particularly in minimally invasive procedures for lung and kidney applications.</p>
                            <p>As a senior mechanical engineer currently working at J&J, I am mainly responsible for system design on the Monarch Surgical Platform, the first robotic platform for minimally invasive diagnostic and therapeutic procedures in the lungs and kidneys.</p>
                            <p>I work on many projects related to the robotic arm and instrument manipulator, both on the hardware and software front. I'm not able to disclose too many details on these projects at the moment, but I will be glad to share my experience when the legal effect expires.</p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/Auris1.png" alt="Monarch Platform" loading="lazy">
                        </div>
                    </div>
                `,
                technology: [
                    'Robotic Arm Design',
                    'Medical Device Design',
                    'Robot Arm Calibration',
                    'NPS Software Development',
                    'System Integration'
                ],
                // development: `
                //     <p>Development of the Monarch Platform involved extensive cross-disciplinary collaboration...</p>
                // `,
                // description: `
                //     <p>The Monarch Platform combines advanced robotics and intuitive user interfaces...</p>
                // `
            }
        },
        'yomi': {
            title: 'Yomi Dental Surgical Robot',
            sections: {
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                                <p>At Neocis, I was instrumental in developing the second generation of the Yomi surgical system, the only FDA-cleared robotic device for dental implant surgery. My contributions included:</p>
                                <ul>
                                    <li>Design and development of joint actuators for a 7-DOF robotic arm</li>
                                    <li>Creation of compact actuator systems and collaboration with OEMs for customization</li>
                                    <li>Implementation of kinematic analysis and simulation for joint load optimization</li>
                                    <li>Development of calibration algorithms and inverse kinematics solver with obstacle avoidance capabilities</li>
                                </ul>
                                <p>The Yomi system provides haptic guidance to dental surgeons while maintaining their direct control of the surgical instruments, combining the precision of robotic technology with the expertise of human practitioners.</p>  
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/Neocis1.png" alt="Yomi Dental Robot" loading="lazy">
                        </div>
                    </div>
                `,
                technology: [
                    'Robotic Actuator Design',
                    'Precision Mechatronics',
                    'Robot Calibration',
                    'System Integration'
                ],
                // development: `
                //     <p>Development of the Yomi Robot emphasized precision and haptic feedback...</p>
                // `,
                // description: `
                //     <p>The Yomi Robot provides haptic guidance to dental surgeons...</p>
                // `
            }
        },
        'harmony': {
            title: 'Harmony SHR Exoskeleton',
            sections:{
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                                <p>During my time at Harmonic Bionics, I contributed to the development of the Harmony SHR, an advanced upper extremity rehabilitation robot. My responsibilities included:</p>
                                <ul>
                                    <li>Design of major mechanical components using various manufacturing techniques</li>
                                    <li>Development of handheld interface devices and custom linear actuator systems</li>
                                    <li>Material validation through simulation and experimental testing</li>
                                    <li>Integration of mechanical and electrical systems for prototype development</li>
                                </ul>
                                <p>The Harmony SHR is designed to facilitate natural movement patterns during rehabilitation, allowing therapists to deliver high quality care while collecting objective patient data.</p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/HB1.png" alt="Harmony SHR" loading="lazy">
                        </div>
                    </div>
                    `,
                technology: [
                    'Exoskeleton Design',
                    'Rehabilitation Robotics',
                    'Linear Actuators',
                    'Human-Robot Interface'
                ],
                // keyFeatures: [
                //     'Upper Extremity Rehabilitation',
                //     'Custom Linear Actuators',
                //     'Patient Data Collection',
                //     'Natural Movement Patterns'
                // ]
            }
        },
        'athena': {
            title: 'Athena Biomimetic Robot',
            sections: {
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                            <p>As team lead for the Athena project at Georgia Tech's LIDAR Lab, I managed the development of a complex biomimetic upper body robot:</p>
                            <ul>
                                <li>Led a team of 12 undergraduate students in system design and integration</li>
                                <li>Implemented a 28-DOF system using linear actuators to mimic human muscle architecture</li>
                                <li>Managed CAD repositories and performed topology optimization for weight reduction</li>
                                <li>Developed control systems for coordinated movement of multiple actuators</li>
                            </ul>
                            <p>The Athena project aims to advance our understanding of human-like movement and control in robotic systems, with potential applications in prosthetics and human-robot interaction.</p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/LIDAR1.png" alt="Athena Biomimetic Robot" loading="lazy">
                        </div>
                    </div>
                `,
                technology: [
                    'Biomimetic Design',
                    'Linear Actuation',
                    'CAD Optimization',
                    'System Integration'
                ],
                keyFeatures: [
                    '28-DOF System',
                    'Muscle-like Actuation',
                    'Topology Optimization',
                    'Team Leadership'
                ]
            }
        },
        'hip-exo': {
            title: 'Assistive Hip Exoskeleton',
            sections: {
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                            <p>Working in the EPIC Lab at Georgia Tech, I contributed to the development of an assistive hip exoskeleton designed to reduce the metabolic cost of walking:</p>
                            <ul>
                                <li>Design and fabrication of series elastic actuator housings and components</li>
                                <li>Development of experimental protocols for system characterization</li>
                                <li>Collection and analysis of metabolic cost data under various conditions</li>
                                <li>Integration of sensors and control systems for real-time assistance</li>
                            </ul>
                            <p>This research aimed to develop more effective assistive devices for individuals with mobility impairments, with a focus on improving energy efficiency during walking.</p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/EPIC1.png" alt="Assistive Hip Exoskeleton" loading="lazy">
                        </div>
                    </div>
                `,
                technology: [
                    'Exoskeleton Design',
                    'Series Elastic Actuators',
                    'Biomechanics',
                    'Data Collection'
                ],
                keyFeatures: [
                    'Metabolic Cost Reduction',
                    'Custom Actuator Design',
                    'Performance Analysis',
                    'User Testing'
                ]
            }
        },
        'dexterous-hand': {
            title: 'Biomimetic Dexterous Hand',
            sections: {
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                            <p>The Biomimetic cable-driven dexterous hand is my winter 2025 project work-in-progress.</p>
                            <p>The goal is to develop a hand that mimics human dexterity, using cable-driven phalangeal joints to minimize distal inertia.</p>
                            <p>As of today, I've completed some single digit prototypes for open-loop control and motorized it. Stay tuned for updates on this exciting project!</p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/hand.gif" alt="Biomimetic Dexterous Hand" loading="lazy">
                        </div>
                    </div>
                `,
                development: `
                    <div class="modal-section overview-section">
                        <div class="overview-image">
                            <img src="assets/images/project_images/Hand/linkage.png" alt="4 bar linkage" loading="lazy">
                        </div>
                        <div class="overview-text">
                            <p>Development of the Hand involves heavy iterative design and testing.</p>
                            <p>More on its way!</p>
                        </div>
                    </div>
                `,
                technology: [
                    'Mechatronics Design',
                    'Cable Driven Actuators',
                    'Rapid Prototyping',
                    'Sensor Fusion'
                ],
            }
        },
        'robotic-mini-golf': {
            title: 'Apex Putter - Robotic Mini-golf',
            sections: {
                overview: `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <h3 class="modal-section-title">Overview</h3>
                            <p>Mini golf presents an intriguing challenge for robotics. While kids rely on intuition and practice, programming a robot to achieve the same feat requires precise control of position and timing. A child needs just a putter, ball, and hole to make a hole-in-one, while a robot needs careful planning.</p>
                            <p>For a Franka Panda robot, the task is more complex. It may not feel competition, but a poorly planned Cartesian path can create significant challenges. In this setup, the robot attempts to putt the ball with just the right force to reach the hole.</p>
                            <p>For this project, I worked on the vision module for the robot, and created mechanical designs for the putter end-effector. In addition, I wrote the demo tasks and created the ROS2 package for Apex-Putter. </p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/Apex-Putter/AP.png" alt="Robotic mini-golf" loading="lazy">
                        </div>
                    </div>
                `,
                Vision: `
                    <div class="modal-section overview-section">
                        <div class="overview-image">
                            <img src="assets/images/project_images/Apex-Putter/AP_vision2.png" alt="Apriltag system" loading="lazy">
                        </div>
                        <div class="overview-text">
                            <p>Vision module is one of the two major modules of this robot. Using a single RealSense D435 camera, this module needs to achieve 2 major functions: register the robot base in the camera frame, and track the ball and hole in the camera frame. </p>
                            <p>In order to achieve this, I used OpenCV to process the camera image, and used AprilTags to locate the position of the robot base. I created a AprilTag mount to provide an initial guess to the robot base transformation, and performed an optical calibration using Kabsch algorithm to improve its accuracy.</p>
                        </div>
                    </div>
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <p>After finding initial robot base transformation, I used a YOLOv8 model to detect the ball and hole in the camera frame. </p>
                            <p>In order to improve it's prediction result, I trained the model using a custom dataset with pictures taken using the very camera, and used the model to predict the position of the ball and hole in the camera frame. </p>
                            <p>Since we now have the camera frame position of all the frames I need, I registered them all together using tf2 and this allows me to look up any transformation as needed.</p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/Apex-Putter/AP_vision3.png" alt="YOLO" loading="lazy">
                        </div>
                    </div>
                `,
                'Mechanical Integration': `
                    <div class="modal-section overview-section">
                        <div class="overview-image">
                            <img src="assets/images/project_images/Apex-Putter/AP_mech1.png" alt="Mechanical Integration" loading="lazy">
                        </div>
                        <div class="overview-text">
                            <p>In order to better integrate with the Franka FER arm, I designed a custom end-effector for the robot. </p>
                            <p>This custom end-effector directly interfaces with an off-the-shelf putter components. The design was iterated a few times to improve clocking to simplify kinematic planning and optimize putting face to make the motion smoother.</p>
                        </div>
                    </div>
                `,
                'Motion Control': `
                    <div class="modal-section overview-section">
                        <div class="overview-text">
                            <p>For the motion control module, I used ROS2 to create a package that interfaces with the robot and the vision module. </p>
                            <p>Using the vision module's output, the motion control module calculates the robot's end-effector position and orientation, and plans a vector path to move the putter to the ball and hole. </p>
                            <p>After the path is planned, the module sends the path to the robot and executes the motion. </p>
                        </div>
                        <div class="overview-image">
                            <img src="assets/images/project_images/Apex-Putter/apex-putter.gif" alt="Motion Control" loading="lazy">
                        </div>
                    </div>
                `,
                technology: [
                    'Kinematic Control',
                    'Computer Vision',
                    'Machine Learning',
                    'YOLO'
                ],
            }
        }
    };
    
    // Updated openModal function
    document.addEventListener('DOMContentLoaded', () => {
        const modal = document.getElementById('project-modal');
        const modalTitle = modal.querySelector('.modal-title');
        const modalDescription = modal.querySelector('.modal-description');
        const closeButton = modal.querySelector('.modal-close');
        const overlay = modal.querySelector('.modal-overlay');

        function openModal(projectId) {
            const project = projectDetails[projectId];
            if (project) {
                modalTitle.textContent = project.title;

                // Generate modal content dynamically
                let modalContent = '';
                for (const [sectionKey, sectionValue] of Object.entries(project.sections)) {
                    if (sectionKey === 'overview') {
                        modalContent += sectionValue; // Use the overview's preformatted structure
                    } else if (sectionKey === 'technology') {
                        modalContent += `
                            <div class="modal-section">
                                <h3 class="modal-section-title">Technology Stack</h3>
                                <div class="tech-list">
                                    ${sectionValue.map(tech => `<span class="tech-item">${tech}</span>`).join('')}
                                </div>
                            </div>
                        `;
                    } else {
                        modalContent += `
                            <div class="modal-section">
                                <h3 class="modal-section-title">${capitalize(sectionKey)}</h3>
                                <div>${sectionValue}</div>
                            </div>
                        `;
                    }
                }

                modalDescription.innerHTML = modalContent;
                modal.classList.add('active');
                document.body.classList.add('modal-open');
            }
        }

        function closeModal() {
            modal.classList.remove('active');
            document.body.classList.remove('modal-open');
        }

        function capitalize(str) {
            return str.charAt(0).toUpperCase() + str.slice(1);
        }

        // Add click listeners to project items
        document.querySelectorAll('.project-item').forEach(item => {
            item.addEventListener('click', () => {
                const projectId = item.getAttribute('data-project-id');
                openModal(projectId);
            });
        });

        // Close modal when clicking close button or overlay
        closeButton.addEventListener('click', closeModal);
        overlay.addEventListener('click', closeModal);

        // Close modal on escape key press
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape') {
                closeModal();
            }
        });
    });
</script>
